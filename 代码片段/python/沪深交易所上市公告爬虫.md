## 深圳证券交易所

```python
# 深圳证券交易所 上市公司公告爬虫
# 主页: http://www.szse.cn/disclosure/listed/notice/index.html
import random

import requests

url = "http://www.szse.cn/api/disc/announcement/annList"

params = {
    "random": random.random(),
}

start_date = ""
end_date = ""
page_num = 1
page_size = 30

data = {
    "seDate": [start_date, end_date],
    "channelCode": ["listedNotice_disc"],
    "pageSize": 30,
    "pageNum": 1
}

resp = requests.post(url, json=data, params=params)
print(resp.text)


pdf_url = "http://disc.static.szse.cn/download/disc/disk02/finalpage/2021-04-15/516df6a8-b71e-454b-83aa-97a4657d63eb.PDF"
content = requests.get(pdf_url).content
with open("aa.pdf", "wb") as f:
    f.write(content)
```



## 上海证券交易所

```python
# 上海证券交易所 上市公司公告爬虫
# http://www.sse.com.cn/disclosure/listedinfo/announcement/

import time

import requests

url = "http://query.sse.com.cn/security/stock/queryCompanyBulletin.do"

start_date = ""
end_date = ""
page_num = 1
page_size = 25

params = {
    # "jsonCallBack": "jsonpCallback76277",
    "isPagination": "true",
    "productId": "",
    "keyWord": "",
    "securityType": "0101,120100,020100,020200,120200",
    "reportType2": "",
    "reportType": "ALL",
    "beginDate": start_date,
    "endDate": end_date,
    "pageHelp.pageSize": "25",
    "pageHelp.pageCount": "50",
    "pageHelp.pageNo": "1",
    "pageHelp.beginPage": "1",
    "pageHelp.cacheSize": "1",
    "pageHelp.endPage": "5",
    "_": int(time.time() * 1000)
}

headers = {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Accept-Language": "en-US,en;q=0.9",
    "Connection": "keep-alive",
    "Cookie": "yfx_c_g_u_id_10000042=_ck21041514471115074143563712733; yfx_f_l_v_t_10000042=f_t_1618469231465__r_t_1618469231465__v_t_1618469231465__r_c_0; VISITED_MENU=%5B%228349%22%5D",
    "DNT": "1",
    "Host": "query.sse.com.cn",
    "Referer": "http://www.sse.com.cn/",
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36",
}

resp = requests.get(url, params=params, headers=headers)
print(resp.text)
```

